{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb12de14",
   "metadata": {},
   "source": [
    "# Twitter US Airline Sentiment Analysis using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72847411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6417449",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3df45301",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['airline_sentiment_gold','name','tweet_id', 'retweet_count','tweet_created','user_timezone','tweet_coord','tweet_location']\n",
    "train1.drop(drop_cols, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a342f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')\n",
    "stops += list(punctuation)\n",
    "stops += ['flight','airline','flights','AA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49e2c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train1['airline_sentiment']\n",
    "train1.drop(\"airline_sentiment\", axis = 1, inplace=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test, Y_train, Y_test = train_test_split(train1, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2c41c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = {'ppl': 'people','cust':'customer','serv':'service','mins':'minutes','hrs':'hours','svc': 'service',\n",
    "           'u':'you','pls':'please'}\n",
    "\n",
    "train_index = train[~train.negativereason_gold.isna()].index\n",
    "test_index = test[~test.negativereason_gold.isna()].index\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    tweet = row.text\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',tweet) #remove links\n",
    "    tweet = re.sub('@[^\\s]+','',tweet) #remove usernames\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet) #remove additional whitespaces\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) #replace #word with word\n",
    "    tweet = tweet.strip('\\'\"') #trim tweet\n",
    "    words = []\n",
    "    for word in tweet.split():\n",
    "#         if not hasNumbers(word):\n",
    "        if word.lower() not in stops:\n",
    "            if word in list(abbreviations.keys()):\n",
    "                words.append(abbreviations[word])\n",
    "            else:\n",
    "                words.append(word.lower())   \n",
    "    tweet = \" \".join(words)\n",
    "    tweet = \" %s %s\" % (tweet, row.airline)\n",
    "    row.text = tweet\n",
    "    if index in train_index:\n",
    "        row.text = \" %s %s\" % (row.text, row.negativereason_gold)\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    tweet = row.text\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',tweet) #remove links\n",
    "    tweet = re.sub('@[^\\s]+','',tweet) #remove usernames\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet) #remove additional whitespaces\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) #replace #word with word\n",
    "    tweet = tweet.strip('\\'\"') #trim tweet\n",
    "    words = []\n",
    "    for word in tweet.split(): \n",
    "#         if not hasNumbers(word):\n",
    "        if word.lower() not in stops:\n",
    "            if word in list(abbreviations.keys()):\n",
    "                words.append(abbreviations[word])\n",
    "            else:\n",
    "                words.append(word.lower())\n",
    "    tweet = \" \".join(words)\n",
    "    tweet = \" %s %s\" % (tweet, row.airline)\n",
    "    row.text = tweet\n",
    "    if index in test_index:\n",
    "        row.text = \" %s %s\" % (row.text, row.negativereason_gold)\n",
    "\n",
    "del train['negativereason_gold']\n",
    "del test['negativereason_gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef8d9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deEmojify(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    row.text = deEmojify(row.text)\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    row.text = deEmojify(row.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11bdc174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    words = row.text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if not hasNumbers(word):\n",
    "            new_words.append(word)\n",
    "    row.text = \" \".join(new_words)\n",
    "    \n",
    "for index, row in test.iterrows():\n",
    "    words = row.text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if not hasNumbers(word):\n",
    "            new_words.append(word)\n",
    "    row.text = \" \".join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "807d11d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Delta</td>\n",
       "      <td>what's easiest way get ticket receipt? get one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7285</th>\n",
       "      <td>Delta</td>\n",
       "      <td>thank you. appreciate that!! Delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>Southwest</td>\n",
       "      <td>i'm really craving pretzels, please send some....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5087</th>\n",
       "      <td>American</td>\n",
       "      <td>great experience again... sfo-jfk... dare say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9313</th>\n",
       "      <td>American</td>\n",
       "      <td>needs get shit together. counter people &amp;amp; ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        airline                                               text\n",
       "11        Delta  what's easiest way get ticket receipt? get one...\n",
       "7285      Delta                 thank you. appreciate that!! Delta\n",
       "1294  Southwest  i'm really craving pretzels, please send some....\n",
       "5087   American  great experience again... sfo-jfk... dare say ...\n",
       "9313   American  needs get shit together. counter people &amp; ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c9d98f",
   "metadata": {},
   "source": [
    "## Creating vocab and data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9176b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = TfidfVectorizer(analyzer='word', max_features=3150, max_df = 0.8, ngram_range=(1,1))\n",
    "train_features= v.fit_transform(train.text)\n",
    "test_features=v.transform(test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62f0340c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7810564663023679"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C = 2.1, solver='liblinear', multi_class='auto')\n",
    "clf.fit(train_features,Y_train)\n",
    "clf.score(test_features, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36a20d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7806921675774134"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel=\"linear\", C= 0.96 , gamma = 'scale')\n",
    "clf.fit(train_features, Y_train)\n",
    "clf.score(test_features, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "218fe5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7479052823315119"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf2 = RandomForestClassifier()\n",
    "clf2.fit(train_features, Y_train)\n",
    "clf2.score(test_features, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3cfcf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7285974499089253"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB() \n",
    "model.fit(train_features, Y_train)\n",
    "model.score(test_features, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169bec29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
